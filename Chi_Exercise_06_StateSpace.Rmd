---
title: "Activity 6 - State-space models"
author: "Student: Chi Chen; Professor: Micheal Dietze"
date: "March 11, 2016"
output: html_document
---
========================================================

## set functions for the JAGS model and shaded CI plot
```{r}
predict.JAGS <- function(time,y) {
library(rjags)
RandomWalk = "
model{

#### Data Model
for(i in 1:n){
y[i] ~ dnorm(x[i],tau_obs)
}

#### Process Model
for(i in 2:n){
x[i]~dnorm(x[i-1],tau_add)
}

#### Priors
x[1] ~ dnorm(x_ic,tau_ic)
tau_obs ~ dgamma(a_obs,r_obs)
tau_add ~ dgamma(a_add,r_add)
}
"

data <- list(y=log(y),n=length(y),x_ic=log(1000),tau_ic=100,a_obs=1,r_obs=1,a_add=1,r_add=1)

nchain = 3
init <- list()
for(i in 1:nchain){
  y.samp = sample(y,length(y),replace=TRUE)
  init[[i]] <- list(tau_add=1/var(diff(log(y.samp))),tau_obs=5/var(log(y.samp)))
}

j.model   <- jags.model (file = textConnection(RandomWalk),
                        data = data,
                        inits = init,
                        n.chains = 3)

## burn-in
jags.out   <- coda.samples (model = j.model,
                            variable.names = c("tau_add","tau_obs"),
                            n.iter = 1000)
# Only to plot 1000 iterations.  
plot(jags.out) 

jags.out   <- coda.samples (model = j.model,
                            variable.names = c("x","tau_add","tau_obs"),
                            n.iter = 10000)

#summary of the final 10000 iteration jags.out
#summary(jags.out)

}


# function for shaded confidence interval
ciEnvelope <- function(x,ylo,yhi,...){
  polygon(cbind(c(x, rev(x), x[1]), c(ylo, rev(yhi),
                                      ylo[1])), border = NA,...) 
}

```

## Original Model (weekly frequency)

```{r}
gflu = read.csv("http://www.google.org/flutrends/about/data/flu/us/data.txt",skip=11)
time = as.Date(gflu$Date)
y = gflu$Massachusetts

# plot original weekly observation data
plot(time,y,type='l',ylab="Flu Index",lwd=2,log='y',main='original weekly observations')

jags.out.original = predict.JAGS(time,y)

par(mfrow=c(1,1))

# plot the original result (weekly observation frequency)
time.rng = c(1,length(time)) ## adjust to zoom in and out
out <- as.matrix(jags.out.original)
ci <- apply(exp(out[,3:ncol(out)]),2,quantile,c(0.025,0.5,0.975))

plot(time,ci[2,],type='n',ylim=range(y,na.rm=TRUE),ylab="Flu Index",log='y',xlim=time[time.rng], main='Model fitted by full weekly observations')
## adjust x-axis label to be monthly if zoomed
if(diff(time.rng) < 100){ 
  axis.Date(1, at=seq(time[time.rng[1]],time[time.rng[2]],by='month'), format = "%Y-%m")
}
ciEnvelope(time,ci[1,],ci[3,],col="lightBlue")
points(time,y,pch="+",cex=0.5)

layout(matrix(c(1,2,3,3),2,2,byrow=TRUE))
hist(1/sqrt(out[,1]),main=colnames(out)[1])
hist(1/sqrt(out[,2]),main=colnames(out)[2])
plot(out[,1],out[,2],pch=".",xlab=colnames(out)[1],ylab=colnames(out)[2])
cor(out[,1:2])

#Save this for later use...
ci.origin = ci
```



Assignment:
-----------

To look at how observation frequency affects data assimilation, convert 3 out of every 4 observations to NA (i.e. treat the data as approximately monthly) and refit the model. 

* Generate a time-series plot for the CI of x that includes the observations (as above). Use a different color and symbol to differentiate observations that were included in the model versus those that were converted to NA's.
* Compare the CI between the two runs.
* Generate a predicted (median) vs observed plot for the data points that were removed
* Comment on the accuracy and precision of the estimates.

### Answer
1. The invertal of CI is much larger in the 2nd run.

2. Generate a predicted (median) vs observed plot for the data points that were removed: Generally, they still have a linear relationship. The linear relationship is stronger when flu index is small(i.e.less than ~1800), and it becomes weaker when flu index get larger. Also, their slope is way off 1. Predicted median is smaller than observed data.

3. Comment on the accuracy and precision: From the histogram of tau_obs and tau_add, those in the 2nd run are much larger than the 1st run. I used the median to represent the accuracy of the two runs. The scatter plots (observed vs predicted median) show that the 1st run is more accurate. In addition, I did OLS to check how much variantion (R square) in observed data can be explianed by the predicted median of the two runs. The results also show that the 1st run is more accurate. In addtion, the two OLS models show that the slope of the 1st run is closer to 1.  About the precision, the confidence interval can tell the whole thing. Obviously, the 1st run is better.
4. So, in this random walk model case, increasing the data frequency can improve our prediction model.

```{r}
time = as.Date(gflu$Date)
y = gflu$Massachusetts
# convert 3 out of every 4 observations to NA
index = seq(1,length(y),4)
y[-index] = NA

y.removed = gflu$Massachusetts
y.removed[index] = NA

jags.out.removed = predict.JAGS(time,y)

time.rng = c(1,length(time)) ## adjust to zoom in and out
out <- as.matrix(jags.out.removed)
ci <- apply(exp(out[,3:ncol(out)]),2,quantile,c(0.025,0.5,0.975))

# Generate a time-series plot for the CI of x that includes the observations.
plot(time,ci[2,],type='n',ylim=range(y,na.rm=TRUE),ylab="Flu Index",log='y',xlim=time[time.rng],main='Model fitted by reduced frequency observations')

## adjust x-axis label to be monthly if zoomed
if(diff(time.rng) < 100){ 
  axis.Date(1, at=seq(time[time.rng[1]],time[time.rng[2]],by='month'), format = "%Y-%m")
}
ciEnvelope(time,ci[1,],ci[3,],col="lightBlue")
points(time,y,pch="+",cex=0.5)
points(time,y.removed,pch='*',col='red',cex=0.5)
legend("topleft",lty=c(1,0,0),c('95% CI','data used to fit model','data not used to fit model'),col=c('lightBlue','black','red'),pch=c(0,'+','*'),lwd=2,cex=0.65)


#Generate a predicted (median) vs observed plot for the data points that were removed
predicted.median = ci[2,]
predicted.median[index]=NA
plot(predicted.median,y.removed,main="Predicted median VS observed (data points that were removed)")
abline(a=0,b=1)

#About the accuracy and precision of the two runs: scatter plot of observed vs predicted median
plot(ci.origin[2,],gflu$Massachusetts,main='The 1st run (all points)')
abline(a=0,b=1)
plot(ci[2,],gflu$Massachusetts,main='The 2nd run (all points)')
abline(a=0,b=1)

# check how much variantion in observed data could be explained by the predicted medians from the two runs
fit1 =  lm(gflu$Massachusett~ ci.origin[2,]) # full data - weekly observations
fit2 =  lm(gflu$Massachusett~ ci[2,]) #removed data - monthly data
summary(fit1)
summary(fit2)


layout(matrix(c(1,2,3,3),2,2,byrow=TRUE))
hist(1/sqrt(out[,1]),main=colnames(out)[1])
hist(1/sqrt(out[,2]),main=colnames(out)[2])
plot(out[,1],out[,2],pch=".",xlab=colnames(out)[1],ylab=colnames(out)[2])
cor(out[,1:2])

```

Extra Credit:
-------------

Return to the original data and instead of removing 3/4 of the data remove the last 40 observations (convert to NA) and refit the model to make a forecast for this period

* Generate a time-series plot for the CI of x that includes the observations (as above but zoom the plot on the last ~80 observations). Use a different color and symbol to differentiate observations that were included in the model versus those that were converted to NA's.
* Comment on how well the random walk model performed (both accuracy and precision) and how it might be modified to improve both these criteria.

### Answer for Extra Credit
1. From the histogram of tau_obs and tau_add, the 3rd run (removed last 40 points) is similar to the 1st run (the full weekly frequency run). 
    In particular, in the time-series plot, the precision is similar in the first 1:580 points, but the pricision explodes in the last 40 predictions. 
    In the  scatter plot of observed vs predicted, we can see the accuracy of the red points (last 40 points that were removed) and the accuracy of the black points (first 580 points that were used to fit the model) are similar. However, I believe the accuracy will get worse in further future predictions due to lacking of data.
    
2. If we want to improve both accuracy and precision, we need to have more observations in those "future period". In this case, **the accuracy and precision of random walk model are largely depended on the current data**. It also implies that the future preditions are largely depended on the current data (if we don't have the future data).

```{r}
time = as.Date(gflu$Date)
y = gflu$Massachusetts
# convert last 40 observations to NA
index = 1:(length(y)-40)
y[-index] = NA

y.removed = gflu$Massachusetts
y.removed[index] = NA

jags.out.removed = predict.JAGS(time,y)

time.rng = c(length(time)-79,length(time)) ## adjust to zoom in and out
out <- as.matrix(jags.out.removed)
ci <- apply(exp(out[,3:ncol(out)]),2,quantile,c(0.025,0.5,0.975))

# Generate a time-series plot for the CI of x that includes the observations.
plot(time,ci[2,],type='n',ylim=range(y,na.rm=TRUE),ylab="Flu Index",log='y',xlim=time[time.rng],main='model fitted by removing last 40 observations')

## adjust x-axis label to be monthly if zoomed
if(diff(time.rng) < 100){ 
  axis.Date(1, at=seq(time[time.rng[1]],time[time.rng[2]],by='month'), format = "%Y-%m")
}
ciEnvelope(time,ci[1,],ci[3,],col="lightBlue")
points(time,y,pch="+",cex=0.5)
points(time,y.removed,pch='*',col='red',cex=0.5)
legend("topleft",lty=c(1,0,0),c('95% CI','data used to fit model','data not used to fit model'),col=c('lightBlue','black','red'),pch=c(0,'+','*'),lwd=2,cex=0.65)

#About the accuracy and precision of the two runs: scatter plot of observed vs predicted median
predicted.median.last40 = predicted.median[(length(y)-40+1):620]
predicted.median.first580 = predicted.median[1:(length(y)-40)]
obs.last40 = gflu$Massachusetts[(length(y)-40+1):620]
obs.first580 = gflu$Massachusetts[1:(length(y)-40)]

plot(ci[2,],gflu$Massachusetts,main='The 3rd run',type='n')
abline(a=0,b=1)
points(predicted.median.first580,obs.first580)
points(predicted.median.last40,obs.last40,col='red')
legend("topleft",lty=c(0,0),c('data used to fit model (first 580 obs)','data not used to fit model(last 40 obs)'),col=c('black','red'),pch=c(1,1),lwd=2,cex=0.65)

layout(matrix(c(1,2,3,3),2,2,byrow=TRUE))
hist(1/sqrt(out[,1]),main=colnames(out)[1])
hist(1/sqrt(out[,2]),main=colnames(out)[2])
plot(out[,1],out[,2],pch=".",xlab=colnames(out)[1],ylab=colnames(out)[2])
cor(out[,1:2])
```